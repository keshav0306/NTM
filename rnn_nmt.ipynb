{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from rnn_layers_torch import *\n",
    "from load_data import *\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, word_to_idx, wordvec_dim, hidden_dim, cell_type, seed, device):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        vocab_size = len(word_to_idx)\n",
    "        self.start_token = word_to_idx[\"<START>\"]\n",
    "        \n",
    "        self.null_token = word_to_idx[\"<NULL>\"]\n",
    "        self.end_token = word_to_idx[\"<END>\"]\n",
    "        self.cell_type = cell_type\n",
    "        self.params = {}\n",
    "\n",
    "        if(seed is not None):\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        self.params[\"W_embed\"] = np.random.randn(vocab_size, wordvec_dim)\n",
    "        self.params[\"W_embed\"] /= 100\n",
    "\n",
    "        dim_mul = {\"lstm\": 4, \"rnn\": 1}[cell_type]\n",
    "        self.params[\"Wx\"] = np.random.randn(wordvec_dim, dim_mul * hidden_dim)\n",
    "        self.params[\"Wx\"] /= np.sqrt(wordvec_dim)\n",
    "        self.params[\"Wh\"] = np.random.randn(hidden_dim, dim_mul * hidden_dim)\n",
    "        self.params[\"Wh\"] /= np.sqrt(hidden_dim)\n",
    "        self.params[\"b\"] = np.zeros(dim_mul * hidden_dim)\n",
    "\n",
    "        self.params[\"W_vocab\"] = np.random.randn(hidden_dim, vocab_size)\n",
    "        self.params[\"W_vocab\"] /= np.sqrt(hidden_dim)\n",
    "        self.params[\"b_vocab\"] = np.zeros(vocab_size)\n",
    "\n",
    "        # Initialize h_init for encoder in its class and for \n",
    "        # decoder just pass it in the forward function as arguement\n",
    "\n",
    "        # self.params[\"h_init\"] = np.random.randn(hidden_dim)\n",
    "\n",
    "        for key in self.params.keys():\n",
    "            self.params[key] = self.params[key].astype(np.float32)\n",
    "            self.params[key] = torch.from_numpy(self.params[key])\n",
    "            self.params[key] = self.params[key].to(device)\n",
    "            self.params[key].requires_grad = True\n",
    "\n",
    "    def forward(self, captions, h_init):\n",
    "        '''returns all the hidden states of the RNN as a tensor of shape (N, T, H)\n",
    "        '''\n",
    "\n",
    "        captions_in = captions[:,:-1]\n",
    "        N = captions.shape[0]\n",
    "        # h0 = torch.tile(h_init, (N, 1))\n",
    "        h0 = h_init\n",
    "        h = None\n",
    "\n",
    "        # Generate word embeddings from captions\n",
    "        inputs = word_embedding_forward(captions_in, self.params[\"W_embed\"])\n",
    "\n",
    "        # RNN forward pass\n",
    "        if(self.cell_type == \"rnn\"):\n",
    "            h = rnn_forward(inputs, h0, self.params[\"Wx\"], self.params[\"Wh\"], self.params[\"b\"])\n",
    "        elif(self.cell_type == \"lstm\"):\n",
    "            h = lstm_forward(inputs, h0, self.params[\"Wx\"], self.params[\"Wh\"], self.params[\"b\"])\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        # Since we dont need the below 2 lines in the encoder, we will just use them in the\n",
    "        # forward function of the decoder class\n",
    "        \n",
    "        # out = temporal_affine_forward(h, self.params[\"W_vocab\"], self.params[\"b_vocab\"])\n",
    "        # loss = temporal_softmax_loss(out, captions_out, mask)\n",
    "\n",
    "        return h\n",
    "    \n",
    "    def load(self, parameters):\n",
    "        for key in self.params.keys():\n",
    "            self.params[key] = parameters[key]\n",
    "            self.params[key].requires_grad = True\n",
    "    \n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, word_to_idx, wordvec_dim, hidden_dim, cell_type, seed, device):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.RNN = RNN(word_to_idx, wordvec_dim, hidden_dim, cell_type, seed, device)\n",
    "        self.h_init = torch.randn(hidden_dim, requires_grad=True)\n",
    "    \n",
    "    def forward(self, captions):\n",
    "        ''' captions are of shape (N, T + 1)\n",
    "        '''\n",
    "        h0 = torch.tile(self.h_init, (captions.shape[0], 1))\n",
    "        hidden_states = self.RNN(captions, h0) # (N, T, H)\n",
    "        # Only returns the end hidden state (the state till the <END> token)\n",
    "        end = torch.where(captions[:,1:] == self.RNN.end_token)\n",
    "        return hidden_states[end]\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, word_to_idx, wordvec_dim, hidden_dim, cell_type, seed, device):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.RNN = RNN(word_to_idx, wordvec_dim, hidden_dim, cell_type, seed, device)\n",
    "\n",
    "    def forward(self, captions, h_init):\n",
    "        ''' captions are of shape (N, T + 1)\n",
    "        '''\n",
    "        hidden_states = self.RNN(captions, h_init) # (N, T, H)\n",
    "        # assume the sentence starts with a <START> token and ends with a <END> token\n",
    "        captions_out = captions[:,1:]\n",
    "\n",
    "        # don't consider the loss where the token is <NULL>\n",
    "        mask = captions_out != self.RNN.null_token\n",
    "\n",
    "        out = temporal_affine_forward(hidden_states, self.RNN.params[\"W_vocab\"], self.RNN.params[\"b_vocab\"])\n",
    "        loss = temporal_softmax_loss(out, captions_out, mask)\n",
    "        return loss\n",
    "\n",
    "class NMT(nn.Module):\n",
    "    def __init__(self, word_to_idx_enc, word_to_idx_dec, wordvec_dim, hidden_dim, cell_type, seed, device):\n",
    "        super(NMT, self).__init__()\n",
    "\n",
    "        # TODO -> allow for different hidden states dimensions for encoder and decoder\n",
    "\n",
    "        self.encoder = Encoder(word_to_idx_enc, wordvec_dim, hidden_dim, cell_type, seed, device)\n",
    "        self.decoder = Decoder(word_to_idx_dec, wordvec_dim, hidden_dim, cell_type, seed, device)\n",
    "        self.mid_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, captions1, captions2):\n",
    "        ''' Both captions1 and captions2 start with <START> and end with <END> and are of shape (N, T + 1)\n",
    "        '''\n",
    "        h_encoder = self.encoder(captions1) # (N, H)\n",
    "        h_init = self.mid_layer(h_encoder)\n",
    "        loss = self.decoder(captions2, h_init)\n",
    "        return loss\n",
    "    \n",
    "    def load(self, weights):\n",
    "        self.encoder.RNN.load(weights[\"params_enc\"])\n",
    "        self.decoder.RNN.load(weights[\"params_dec\"])\n",
    "        self.mid_layer.weight = nn.Parameter(weights[\"mid_layer\"][0])\n",
    "        self.mid_layer.bias = nn.Parameter(weights[\"mid_layer\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_en = \"english.txt\"\n",
    "file_es = \"spanish.txt\"\n",
    "word_to_idx = None\n",
    "\n",
    "word_to_idx_en = make_dict(file_en)\n",
    "word_to_idx_es = make_dict(file_es)\n",
    "\n",
    "reverse_dict_en = {}\n",
    "reverse_dict_es = {}\n",
    "\n",
    "for keys, value in word_to_idx_en.items():\n",
    "    reverse_dict_en[value] = keys\n",
    "\n",
    "for keys, value in word_to_idx_es.items():\n",
    "    reverse_dict_es[value] = keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the tensors will be allocated by default on the device\n",
    "# Except some cases where we are using torch.from_numpy. Why?\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)\n",
    "\n",
    "# Common Parameters For Both Encoder and Decoder\n",
    "# TODO make the parameters different for both of them, define separately\n",
    "hidden_dim = 256\n",
    "word_vec_dim = 256\n",
    "seed = 4\n",
    "architecture = \"lstm\"\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "# Create a NTM instance\n",
    "nmt = NMT(word_to_idx_en, word_to_idx_es, word_vec_dim, hidden_dim, architecture, seed, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> if the house agrees i shall do as mr evans has suggested <END> \n",
      "<START> si la asamblea esta de acuerdo hare lo que el senor evans acaba de sugerir <END> \n"
     ]
    }
   ],
   "source": [
    "# Uncomment below lines and comment line in the for loop for cheking overfitting\n",
    "data_en, data_es = load_data_nmt(word_to_idx_en, word_to_idx_es, file_en, file_es, lines_count=1, max_train=1, hardcode=12)\n",
    "\n",
    "for i in range(len(data_en)):\n",
    "    words = [reverse_dict_en[val] for val in data_en[i]]\n",
    "    for word in words:\n",
    "        print(word + \" \", end = \"\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "for i in range(len(data_es)):\n",
    "    words = [reverse_dict_es[val] for val in data_es[i]]\n",
    "    for word in words:\n",
    "        print(word + \" \", end = \"\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "data_en = torch.from_numpy(data_en)\n",
    "data_es = torch.from_numpy(data_es)\n",
    "data_en = data_en.to(device)\n",
    "data_es = data_es.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = \"check.pt\"\n",
    "loaded_weights = torch.load(weights_file, map_location=device)\n",
    "nmt.load(loaded_weights)\n",
    "\n",
    "parameters = [nmt.mid_layer.weight, nmt.mid_layer.bias]\n",
    "\n",
    "for key in nmt.encoder.RNN.params.keys():\n",
    "    parameters.append(nmt.encoder.RNN.params[key])\n",
    "\n",
    "for key in nmt.decoder.RNN.params.keys():\n",
    "    parameters.append(nmt.decoder.RNN.params[key])\n",
    "\n",
    "optimizer = optim.Adam(parameters, lr=learning_rate)\n",
    "optimizer.load_state_dict(loaded_weights[\"optime\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n",
      "tensor(57.7629, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    # data_en, data_es = load_data_nmt(word_to_idx_en, word_to_idx_es, file_en, file_es, lines_count=1, max_train=50)\n",
    "    # data_en = torch.from_numpy(data_en)\n",
    "    # data_es = torch.from_numpy(data_es)\n",
    "    # data_en = data_en.to(device)\n",
    "    # data_es = data_es.to(device)\n",
    "\n",
    "    loss = nmt(data_en, data_es)\n",
    "\n",
    "    print(loss)\n",
    "\n",
    "    for param in parameters:\n",
    "        param.retain_grad()\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    if i%100 == 0:\n",
    "        torch.save({\n",
    "            \"params_enc\" : nmt.encoder.RNN.params,\n",
    "            \"params_dec\" : nmt.decoder.RNN.params,\n",
    "            \"mid_layer\" : (nmt.mid_layer.weight, nmt.mid_layer.bias),\n",
    "            \"optime\" : optimizer.state_dict()\n",
    "        }, \"check.pt\")\n",
    "\n",
    "torch.save({\n",
    "    \"params_enc\" : nmt.encoder.RNN.params,\n",
    "    \"params_dec\" : nmt.decoder.RNN.params,\n",
    "    \"mid_layer\" : (nmt.mid_layer.weight, nmt.mid_layer.bias),\n",
    "    \"optime\" : optimizer.state_dict()\n",
    "}, \"check.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paquetes preferible fuerza que ha dicho el sr presidente <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> ******\n"
     ]
    }
   ],
   "source": [
    "# The constituent of the sentence (either words or letters should be a part of word_to_dict)\n",
    "# Choose the words carefully!\n",
    "\n",
    "str = \"<START> \"\n",
    "start_string = \"we participated in elections characteristic of the european union\"\n",
    "start_string = str + start_string + \" <END>\"\n",
    "\n",
    "words = start_string.split()\n",
    "num_len_start = len(words)\n",
    "word_enc = [word_to_idx_en[word] for word in words]\n",
    "word_enc = torch.tensor(word_enc).unsqueeze(0)\n",
    "\n",
    "prev_h = nmt.encoder(word_enc) # (1, hidden_state_dim)\n",
    "prev_c = torch.zeros((1, prev_h.shape[1])) \n",
    "\n",
    "start_weights = nmt.decoder.RNN.params['W_embed'][nmt.decoder.RNN.start_token]\n",
    "start_weights = torch.unsqueeze(start_weights, 0) # (1, word_vec_dim)\n",
    "\n",
    "curr_x = start_weights\n",
    "\n",
    "next_h, next_c = None, None\n",
    "max_length = 60\n",
    "\n",
    "rnn = nmt.decoder.RNN\n",
    "captions = rnn.null_token * torch.ones((1, max_length), dtype=torch.int32)\n",
    "\n",
    "letter_or_word = words\n",
    "\n",
    "for i in range(max_length):\n",
    "    if(architecture == \"rnn\"):\n",
    "        next_h = rnn_step_forward(curr_x, prev_h, rnn.params[\"Wx\"], rnn.params[\"Wh\"], rnn.params[\"b\"])\n",
    "    else:\n",
    "        next_h, next_c = lstm_step_forward(curr_x, prev_h, prev_c, rnn.params[\"Wx\"], rnn.params[\"Wh\"], rnn.params[\"b\"])\n",
    "\n",
    "    out = affine_forward(next_h, rnn.params[\"W_vocab\"], rnn.params[\"b_vocab\"])\n",
    "    T = 0.2\n",
    "    out = torch.exp(out/T)\n",
    "    out = out / torch.sum(out, dim = 1)\n",
    "    indices = torch.multinomial(out, 1).squeeze(0)\n",
    "    captions[0, i] = indices\n",
    "    prev_h = next_h\n",
    "    prev_c = next_c\n",
    "    curr_x = rnn.params[\"W_embed\"][indices]\n",
    "\n",
    "captions = captions.tolist()\n",
    "\n",
    "for i in range(len(captions)):\n",
    "    words = [reverse_dict_es[val] for val in captions[i]]\n",
    "    for word in words:\n",
    "        print(word + \" \", end = \"\")\n",
    "    print(\"******\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
